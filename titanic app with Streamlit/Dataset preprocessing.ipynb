{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we train the the predictors on the Tatinic dataset and crate the Streamlit app, some preprocessing is necessary. \n",
    "- We need to address the missing values in the dataset\n",
    "- Next, we need to understand which columns have a high information potential and which columns can be merged or dropped altogether\n",
    "- Finally, we need to transform categorical features to numerical ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the dataset and taking an overall look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('titanic_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset includes 891 entries and 12 columns. We notice that the 'Age' column is missing 177 values, the 'Cabin' column is missing 687 values and the 'Embarked' column is missing 2 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Age' column**\n",
    "\n",
    "We will replace the missing vaues with the median passenger age per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    37.0\n",
       "2    29.0\n",
       "3    24.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(['Pclass'])['Age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_by_class(df):\n",
    "    Age = df[0]\n",
    "    Pclass = df[1]\n",
    "    \n",
    "    if pd.isnull(Age):\n",
    "        if Pclass == 1: return 37\n",
    "        elif Pclass == 2: return 29\n",
    "        else: return 24\n",
    "    else:\n",
    "        return Age\n",
    "\n",
    "titanic['Age'] = titanic[['Age' , 'Pclass']].apply(age_by_class, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Cabin' column**\n",
    "\n",
    "While an overwhelming amount of entries are missing in the 'Cabin' column, it does seem to be a good predictor of whether the passenger survived or not so it is probably a bad idea to dismiss it altogether. Instead, it can be transformed into a binary indicator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin\n",
       "False    204\n",
       "True     687\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(titanic['Cabin'].isnull())['Survived'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over three times more passengers whom had a cabin number survived letting believe that wealthier passangers had more chances to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Cabin_ind'] = np.where(titanic['Cabin'].isnull(), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(columns =['Cabin'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Embarked' column**\n",
    "\n",
    "It looks like the wide majority of passengers embarked in Southampton and only relatively few passengers joined in the other two ports. The more, when looking at the survival rate by port and by class, the chance of survival seems to be determined by the class as the mean survival rate is almost identical for passengers embarked in any port. An exception is the survival rate for the 3rd class for passengers from Southampton, but this is explained by the sheer number of people who embarked in Southampton on the 3rd class. Therefore, we will drop the 'Embarked' column and keep the 'Pclass' one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked  Survived\n",
       "C         0            75\n",
       "          1            93\n",
       "Q         0            47\n",
       "          1            30\n",
       "S         0           427\n",
       "          1           217\n",
       "Name: PassengerId, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(['Embarked', 'Survived'])['PassengerId'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked  Pclass\n",
       "C         1         0.694118\n",
       "          2         0.529412\n",
       "          3         0.378788\n",
       "Q         1         0.500000\n",
       "          2         0.666667\n",
       "          3         0.375000\n",
       "S         1         0.582677\n",
       "          2         0.463415\n",
       "          3         0.189802\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(['Embarked', 'Pclass'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(columns =['Embarked'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'SibSp' and 'Parch' columns**\n",
    "\n",
    "First, we will merge these columns into a single one called 'Family'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['Family'] = titanic['SibSp'] + titanic['Parch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Family\n",
       "False    0.303538\n",
       "True     0.505650\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.groupby(titanic['Family']!=0)['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that people travelling with family had more chances to survive than people travelling alone. We will, therefore, binarise this information by '0' -> passengers travelling alone and '1' -> passengers traveling not alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.loc[titanic['Family'] > 0, 'Not_alone'] = 1\n",
    "titanic.loc[titanic['Family'] == 0, 'Not_alone'] = 0\n",
    "titanic['Not_alone'] = titanic['Not_alone'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(columns =['SibSp', 'Parch', 'Family'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Ticket', 'Fare', 'Name', 'PassengerId' columns**\n",
    "\n",
    "We will drop these columns for the following reasons:\n",
    "- 'Ticket' and 'Name' are strings and feable predictors of survival\n",
    "- 'PassengerId' is the dataframe index\n",
    "- 'Fare' is strongly correlated the class as passengers in upper classes payed more for their ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.drop(columns =['Name', 'Ticket', 'Fare', 'PassengerId'], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features to numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**'Sex' column**\n",
    "\n",
    "We will binarize the 'Sex' column values so as a male passenger will be represented by '1' and a female passenger represented by '0'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male is 1\n",
    "titanic['Sex'] = pd.get_dummies(titanic['Sex'], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our preprocessed dataframe will look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Cabin_ind</th>\n",
       "      <th>Not_alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  Cabin_ind  Not_alone\n",
       "0         0       3    1  22.0          0          1\n",
       "1         1       1    0  38.0          1          1\n",
       "2         1       3    0  26.0          0          0\n",
       "3         1       1    0  35.0          1          1\n",
       "4         0       3    1  35.0          0          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"Survived\"\n",
    "\n",
    "y = titanic[target].copy() # get labels\n",
    "X = titanic.drop(target, axis=1) # drop labels for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save a copy of the dataset without the labels to be used in the Streamlit application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titanic.to_csv('titanic_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Survival rate prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first test a baseline prediction using for three estimators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raw_predictor(predictor):\n",
    "    for item in predictor:\n",
    "        model = item\n",
    "        cv_scores = cross_val_score(model, X_train, y_train, cv=10, n_jobs = -1)\n",
    "        print(str(item).split(\"(\")[0], \"Scores:\", cv_scores)\n",
    "        print(str(item).split(\"(\")[0], \"Mean:\", cv_scores.mean())\n",
    "        print(str(item).split(\"(\")[0], \"Standard deviation:\", cv_scores.std())  \n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Scores: [0.89552239 0.70149254 0.80597015 0.85074627 0.80597015 0.70149254\n",
      " 0.70149254 0.79104478 0.75757576 0.89393939]\n",
      "LogisticRegression Mean: 0.7905246494798733\n",
      "LogisticRegression Standard deviation: 0.07119617673807932\n",
      "\n",
      "\n",
      "RandomForestClassifier Scores: [0.88059701 0.76119403 0.8358209  0.85074627 0.73134328 0.74626866\n",
      " 0.73134328 0.74626866 0.78787879 0.86363636]\n",
      "RandomForestClassifier Mean: 0.793509724106739\n",
      "RandomForestClassifier Standard deviation: 0.055531054502725385\n",
      "\n",
      "\n",
      "SVC Scores: [0.64179104 0.65671642 0.65671642 0.68656716 0.64179104 0.6119403\n",
      " 0.67164179 0.62686567 0.60606061 0.65151515]\n",
      "SVC Mean: 0.6451605608322026\n",
      "SVC Standard deviation: 0.023901927499956427\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictor = [LogisticRegression(), RandomForestClassifier(), SVC()]\n",
    "\n",
    "test_raw_predictor(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will fine tune the estimators and test their performancce in an ensemble learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fine_tune_predictor(predictor, grid):\n",
    "    predictor_cv = GridSearchCV(predictor, grid, cv=10)\n",
    "    predictor_cv.fit(X_train, y_train)\n",
    "    print(\"Tuned hyperparameters :(best parameters) \", predictor_cv.best_params_)\n",
    "    print(\"Accuracy :\",predictor_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_svm = {'C':[1, 10, 100],'kernel':['rbf','linear'], 'gamma':[0.1,'auto', 10], 'degree':[3,4,10]}\n",
    "\n",
    "parameters_rf = {'n_estimators': [10, 100,50], 'min_samples_leaf': [2,4], 'min_samples_split':[2,6],\n",
    "                 'bootstrap':[True, False], 'max_depth': [10, 50, 100]}\n",
    "\n",
    "parameters_lr = {'penalty': ['l1', 'l2'],'C':[0.001,0.01,1,10,100], 'solver':['liblinear', 'saga']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned hyperparameters :(best parameters)  {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy : 0.7935323383084577\n"
     ]
    }
   ],
   "source": [
    "fine_tune_predictor(LogisticRegression(max_iter=10000), parameters_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned hyperparameters :(best parameters)  {'bootstrap': True, 'max_depth': 50, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Accuracy : 0.8174581637268205\n"
     ]
    }
   ],
   "source": [
    "fine_tune_predictor(RandomForestClassifier(n_jobs = -1), parameters_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned hyperparameters :(best parameters)  {'C': 10, 'degree': 3, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Accuracy : 0.7981004070556309\n"
     ]
    }
   ],
   "source": [
    "fine_tune_predictor(SVC(), parameters_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", penalty =\"l1\", C=1, random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, bootstrap=False, max_depth=10, min_samples_leaf=2, \n",
    "                                 min_samples_split=6, random_state=42)\n",
    "svm_clf = SVC(gamma=0.1, degree=3, C=10, kernel='rbf', probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.8026905829596412\n",
      "RandomForestClassifier 0.8116591928251121\n",
      "SVC 0.8026905829596412\n",
      "VotingClassifier 0.7982062780269058\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictors are ready now to be deployed in the application. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
